{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 AIML Hackathon 2026 - Starter Notebook\n",
    "\n",
    "Welcome to the Passage Ranking Challenge! This notebook will guide you through:\n",
    "1. Setting up your environment.\n",
    "2. Downloading the dataset.\n",
    "3. Generating a **Random Baseline** submission.\n",
    "\n",
    "**Goal**: Rank passages for each query in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "We need `pandas` and `pyarrow` for data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all dependencies explicitly\n",
    "!pip install torch>=2.0.0 transformers>=4.30.0 sentence-transformers>=2.2.0 pytorch-lightning>=2.0.0 \\\n",
    "    scikit-learn>=1.3.0 xgboost>=2.0.0 optuna>=3.4.0 gensim>=4.3.0 \\\n",
    "    numpy>=1.24.0 pandas>=2.0.0 tqdm>=4.65.0 rank_bm25>=0.2.2 \\\n",
    "    nltk>=3.8.0 matplotlib>=3.7.0 requests>=2.31.0 ir_datasets>=0.5.0 pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset\n",
    "Download the competition dataset from GitHub releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "# Dataset URL (from GitHub Releases)\n",
    "DATASET_URL = \"https://github.com/fabsilvestri/aiml_hackathon_data/releases/download/v1.0/kaggle_data.zip\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# Always download the dataset\n",
    "print(\"Downloading dataset...\")\n",
    "zip_path = \"kaggle_data.zip\"\n",
    "\n",
    "# Download\n",
    "print(f\"Downloading from {DATASET_URL}...\")\n",
    "urllib.request.urlretrieve(DATASET_URL, zip_path)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "# Extract INTO data/ folder\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(\"Extracting...\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "    zf.extractall(DATA_DIR)\n",
    "print(f\"Extracted to {DATA_DIR}/\")\n",
    "\n",
    "# Cleanup zip\n",
    "os.remove(zip_path)\n",
    "\n",
    "# List files\n",
    "print(\"\\nDataset files:\")\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "Load the test queries and passage collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Resources\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Load test queries\n",
    "test_queries = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "print(f\"Loaded {len(test_queries)} test queries.\")\n",
    "\n",
    "# Load collection\n",
    "collection = pd.read_parquet(f\"{DATA_DIR}/collection.parquet\")\n",
    "all_pids = collection['pid'].astype(str).tolist()\n",
    "print(f\"Loaded {len(all_pids)} passages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Random Baseline\n",
    "For each query, we randomly select 10 passages from the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Random Rankings\n",
    "print(\"Generating random rankings...\")\n",
    "results = []\n",
    "for qid in test_queries['id']:\n",
    "    # Randomly sample 10 PIDs from the collection\n",
    "    ranked_pids = random.sample(all_pids, 10)\n",
    "    results.append({\n",
    "        'id': str(qid),\n",
    "        'expected': \" \".join(ranked_pids)\n",
    "    })\n",
    "\n",
    "print(f\"Generated rankings for {len(results)} queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Submission\n",
    "Save the results to CSV format for Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission = pd.DataFrame(results)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"Created submission.csv with {len(submission)} rows.\")\n",
    "print(\"\\n\u2705 You can now submit this file to the Kaggle Leaderboard!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}